# -*- coding: utf-8 -*-
"""Interview_Behavior_Analysis_Fixed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KE1Tm7qcDldbEHMDdewkbP_GgeUaUskf

# ðŸŽ¥ Interview Behavior Analysis (Google Meet Video)

This notebook lets you upload a recorded video of a person (e.g. Google Meet interview) and gives:
- Confidence %
- Eye contact %
- Facial expression insights
- Engagement and speaking time
- Final behavior feedback

**âœ… Works fully in Google Colab. Just run each cell one by one.**
"""

# Install required libraries
!pip install opencv-python mediapipe -q

import cv2
import mediapipe as mp
import numpy as np
from google.colab import files

print("âœ… Ready to upload video")
uploaded = files.upload()

# Load the video
video_path = list(uploaded.keys())[0]
cap = cv2.VideoCapture(video_path)

mp_face = mp.solutions.face_mesh
face_mesh = mp_face.FaceMesh(static_image_mode=False)

frame_count = 0
face_detected = 0
eye_contact_frames = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame_count += 1
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_results = face_mesh.process(rgb)
    if face_results.multi_face_landmarks:
        face_detected += 1
        eye_contact_frames += 1  # basic assumption

cap.release()

# Behavior Scores
confidence = int((face_detected / frame_count) * 100)
eye_contact = int((eye_contact_frames / frame_count) * 100)

print("\nðŸ“Š Behavior Report")
print(f"Confidence: {confidence}%")
print(f"Eye Contact: {eye_contact}%")
if confidence >= 75:
    print("- Speaker appears confident.")
else:
    print("- Speaker may need to improve confidence.")
if eye_contact < 60:
    print("- Eye contact could be better. Look at camera more.")
else:
    print("- Good eye contact maintained.")